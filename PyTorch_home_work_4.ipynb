{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687a1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de928cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR10(root='D:/Data/Study/cifar10', train=True, download=True)\n",
    "\n",
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
    "    return X_train, X_test\n",
    "\n",
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]\n",
    "    \n",
    "trans_actions = transforms.Compose([transforms.Resize(44),\n",
    "                                    transforms.RandomCrop(32, padding=4), \n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb5bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77936d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (dp_three): Dropout(p=0.2, inplace=False)\n",
      "  (dp_four): Dropout(p=0.2, inplace=False)\n",
      "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_two): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_three): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=480, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dp_three = nn.Dropout(0.2)\n",
    "        self.dp_four = nn.Dropout(0.2)\n",
    "        \n",
    "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
    "        self.conv_one = torch.nn.Conv2d(3, 30, 3)\n",
    "        self.bn_two = torch.nn.BatchNorm2d(30) \n",
    "        self.conv_two = torch.nn.Conv2d(30, 60, 3)\n",
    "        self.bn_three = torch.nn.BatchNorm2d(60)\n",
    "        self.conv_three = torch.nn.Conv2d(60, 120, 3)\n",
    "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
    "        self.fc1 = torch.nn.Linear(480, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 60)\n",
    "        self.out = torch.nn.Linear(60, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn_one(x)\n",
    "        x = self.conv_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_two(x)\n",
    "        x = self.conv_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_three(x)\n",
    "        x = self.conv_three(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_four(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp_three(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp_four(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "       \n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4b420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fd761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
      "            Conv2d-2           [-1, 30, 30, 30]             840\n",
      "       BatchNorm2d-3           [-1, 30, 15, 15]              60\n",
      "            Conv2d-4           [-1, 60, 13, 13]          16,260\n",
      "       BatchNorm2d-5             [-1, 60, 6, 6]             120\n",
      "            Conv2d-6            [-1, 120, 4, 4]          64,920\n",
      "       BatchNorm2d-7            [-1, 120, 2, 2]             240\n",
      "           Dropout-8                  [-1, 480]               0\n",
      "            Linear-9                  [-1, 200]          96,200\n",
      "          Dropout-10                  [-1, 200]               0\n",
      "           Linear-11                   [-1, 60]          12,060\n",
      "           Linear-12                   [-1, 10]             610\n",
      "================================================================\n",
      "Total params: 191,316\n",
      "Trainable params: 191,316\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.40\n",
      "Params size (MB): 0.73\n",
      "Estimated Total Size (MB): 1.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e74bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10]. Step [1 / 372].Loss 0.018. Acc: 0.055. Test acc: 0.093\n",
      "Epoch [1 / 10]. Step [301 / 372].Loss 0.015. Acc: 0.295. Test acc: 0.369\n",
      "Epoch [2 / 10]. Step [1 / 372].Loss 0.015. Acc: 0.336. Test acc: 0.432\n",
      "Epoch [2 / 10]. Step [301 / 372].Loss 0.013. Acc: 0.403. Test acc: 0.481\n",
      "Epoch [3 / 10]. Step [1 / 372].Loss 0.011. Acc: 0.477. Test acc: 0.412\n",
      "Epoch [3 / 10]. Step [301 / 372].Loss 0.012. Acc: 0.451. Test acc: 0.494\n",
      "Epoch [4 / 10]. Step [1 / 372].Loss 0.011. Acc: 0.492. Test acc: 0.486\n",
      "Epoch [4 / 10]. Step [301 / 372].Loss 0.011. Acc: 0.477. Test acc: 0.496\n",
      "Epoch [5 / 10]. Step [1 / 372].Loss 0.010. Acc: 0.492. Test acc: 0.531\n",
      "Epoch [5 / 10]. Step [301 / 372].Loss 0.011. Acc: 0.493. Test acc: 0.559\n",
      "Epoch [6 / 10]. Step [1 / 372].Loss 0.012. Acc: 0.477. Test acc: 0.537\n",
      "Epoch [6 / 10]. Step [301 / 372].Loss 0.011. Acc: 0.509. Test acc: 0.482\n",
      "Epoch [7 / 10]. Step [1 / 372].Loss 0.011. Acc: 0.555. Test acc: 0.530\n",
      "Epoch [7 / 10]. Step [301 / 372].Loss 0.011. Acc: 0.519. Test acc: 0.566\n",
      "Epoch [8 / 10]. Step [1 / 372].Loss 0.010. Acc: 0.500. Test acc: 0.555\n",
      "Epoch [8 / 10]. Step [301 / 372].Loss 0.010. Acc: 0.529. Test acc: 0.553\n",
      "Epoch [9 / 10]. Step [1 / 372].Loss 0.011. Acc: 0.562. Test acc: 0.550\n",
      "Epoch [9 / 10]. Step [301 / 372].Loss 0.010. Acc: 0.535. Test acc: 0.565\n",
      "Epoch [10 / 10]. Step [1 / 372].Loss 0.011. Acc: 0.492. Test acc: 0.568\n",
      "Epoch [10 / 10]. Step [301 / 372].Loss 0.010. Acc: 0.546. Test acc: 0.565\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        if i % 300 == 0:\n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1} / {num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1} / {len(train_loader)}].' \\\n",
    "                  f'Loss {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "            \n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader, 0):\n",
    "                test_outputs = net(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "            \n",
    "        net.train()\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cceed81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.87\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 103.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "summary(resnet.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d971ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244ba983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22084c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 23,528,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 95.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "in_features = resnet.fc.in_features\n",
    "fc = nn.Linear(in_features=in_features, out_features = 10)\n",
    "resnet.fc = fc\n",
    "summary(resnet.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460fa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_dataloader,\n",
    "          test_dataloader,\n",
    "          print_every,\n",
    "          num_epoch):\n",
    "    steps = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        running_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        start_time = time()\n",
    "        iter_time = time()\n",
    "         \n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            step += 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "#              for i, data in enumerate(train_loader, 0):\n",
    "#         inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            correct_train += (torch.max(output, dim=1)[]==labels).sum()\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Logging\n",
    "            if steps % print_every == 0:\n",
    "                print(f'Epoch [{epoch + 1}] / [{num_epochs}]. Batch [{i + 1}]/[{len(train_dataloader)}].', end=' ')\n",
    "                print(f'Train Loss {running_loss / steps:.3f}.', end=' ')\n",
    "                print(f'Train acc: {correct_train / total_train * 100:.3f}', end=' ')\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    correct_val, total_val = 0, 0\n",
    "                    val_loss = 0\n",
    "                    for images, labels in test_dataloader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        output = model(images)\n",
    "                        loss = criterion(output, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        correct_val += (torch.max(output, dim=1)[1]==labels).sum()\n",
    "                        total_val += labels.size(0)\n",
    "                print(f'Val loss {val_loss / len(test_dataloader):.3f}. Val acc {correct_val / total_val * 100:.3f}.', end = ' ')\n",
    "                print(f'Took {time() - iter_time:.3f} seconds')\n",
    "                iter_time = time()\n",
    "                \n",
    "                train_losses.append(running_loss / total_loss)\n",
    "                val_losses.append(val_loss / total_val)\n",
    "        print(f'Epoch took {time()-start_time}')\n",
    "        torch.save(model, f'checkpoint_{correct_val /total_val*100:.2f}')\n",
    "    return model, train_losses, val_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
